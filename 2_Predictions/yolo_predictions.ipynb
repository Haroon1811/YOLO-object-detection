{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91a0cf93-2c4b-4330-ad86-9bedbba182a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader as sl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75767678-dc8e-4527-95fc-aeba1cb0e6c9",
   "metadata": {},
   "source": [
    "# Predictions:\n",
    "\"\"\"\n",
    "1. load yaml file and yolo model\n",
    "2. laod one image and get the yolo predictions(detections) from the image\n",
    "3. do non maximum suppression----make sure the bounding boxes are correct for multiple bounding boxes --- do this filter\n",
    "4. draw the bounding bax \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc97f17a-5320-46b5-964e-e60fc93cf2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'car', 'chair', 'bottle', 'potted plant', 'sheep', 'cow', 'boat', 'horse', 'motor bike', 'bicycle', 'dog', 'bird', 'sofa', 'bus', 'tv monitor', 'cat', 'train', 'aeroplane', 'dining table']\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the YAML file ----file data.yaml\n",
    "with open('data.yaml',mode='r') as f:\n",
    "    data_yaml = yaml.load(f, Loader=sl)\n",
    "# call names from the data.yaml file -- this is what will be required \n",
    "labels = data_yaml['names']\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3030bbf9-cc9f-43ad-8613-119c9597bf31",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "This code is using OpenCV's deep neural network (DNN) module to load and \n",
    "configure a YOLO (You Only Look Once) model from a pre-trained ONNX (Open Neural Network Exchange) file. Let's break down each part:\n",
    "\n",
    "    yolo = cv.dnn.readNetFromONNX('./Model/weights/best.onnx'):\n",
    "        This line loads a pre-trained model saved in the ONNX format.\n",
    "        The ONNX file (best.onnx) contains the structure and trained weights of a YOLO model.\n",
    "        OpenCV provides the readNetFromONNX() function to read the ONNX model \n",
    "        and prepare it for inference (predicting results based on input data).\n",
    "\n",
    "    yolo.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV):\n",
    "        This specifies that the model should use OpenCV as the backend for inference.\n",
    "        OpenCV has different backends for executing neural networks, such as OpenCV itself, CUDA, or Intel's OpenVINO. \n",
    "        Here, we are setting the backend to OpenCV's default DNN module.\n",
    "\n",
    "    yolo.setPreferableTarget(cv.dnn.DNN_TARGET_CPU):\n",
    "        This tells OpenCV to use the CPU as the hardware target for running inference.\n",
    "        Since the model was likely trained in a GPU environment (as indicated by the comment), \n",
    "        this line ensures that the model will run on the CPU for inference (prediction) instead of requiring a GPU.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ec9f033-bc4b-4fee-b080-1711860e7a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Load YOLO Model\n",
    "yolo = cv.dnn.readNetFromONNX('./Model/weights/best.onnx')\n",
    "# Set the backend ---since we trained in GPU environment so we need to specify that we need to use target CPU\n",
    "yolo.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "yolo.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b8a3b08-87d1-412f-ae5e-f13e4fe19b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "956 1920 3\n"
     ]
    }
   ],
   "source": [
    "# 2. Load the image for testing the model\n",
    "img = cv.imread('./street_image.jpg')\n",
    "image = img.copy()          # making  a copy of the loaded image file\n",
    "\n",
    "cv.imshow('image',image)     # for showing the image in seperate window\n",
    "cv.waitKey(0)\n",
    "#cv.destroyALLWindows()\n",
    "\n",
    "# calculate the rows(height) and columns(width) and depth(color_channels) from the image\n",
    "rows, cols, d = image.shape\n",
    "print(rows, cols, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c66a0b80-8560-41ed-b3de-4a9051c6dd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 25200, 25)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\ncv.imshow('Input image', input_image)\\ncv.waitKey(0)\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.1 Get the yolo predictions from the image \n",
    "\"\"\"\n",
    "first we need to convert the image into square matrix --- ONE WAY TO DO THIS IS :\n",
    "CREATE A DUMMY MATRIX AND OVERLAY THE IMAGE ON IT ----- DEFINE A SQUARE MATRIX WITH MAX(ROWS AND COLUMNS)\n",
    "\"\"\"\n",
    "# Step 1:convert the image into square image (array)\n",
    "max_rc = max(rows,cols)\n",
    "input_image = np.zeros((max_rc,max_rc,3),dtype=np.uint8)    # uint8-- unsigned int bit 8\n",
    "# overlap the image on this square matrix \n",
    "input_image[0:rows,0:cols] = image\n",
    "\n",
    "# Step 2: pass the square image to yolo model to get predictions\n",
    "# yolo model trained with input size of 640*640\n",
    "INPUT_WH_YOLO =640\n",
    "# find blob from image \n",
    "blob = cv.dnn.blobFromImage(input_image,1/255,(INPUT_WH_YOLO,INPUT_WH_YOLO),swapRB=True,crop=False)       # scale factor-- normalised by 255\n",
    "# set the yolo input \n",
    "yolo.setInput(blob)\n",
    "# predictions from yolo model\n",
    "preds = yolo.forward()\n",
    "\n",
    "\n",
    "\n",
    "print(preds.shape)      \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "cv.imshow('Input image', input_image)\n",
    "cv.waitKey(0)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ea9157",
   "metadata": {},
   "source": [
    "# 25200 rows(number of bounding boxes detected from the image) and \n",
    "                        # 25 columns(for each and every bounding box information in the columns) --- divided into first five columns and 20 columns \n",
    "                        # first 5 columns show center_x, center_y, w, h and confidence score \n",
    "                        # other 20 show probability(clasification) score of each and every class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cf04a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. NON MAXIMUM SUPPRESSION:\n",
    "\"\"\"\n",
    "Remove the duplicate Bounding Boxes(detections) and select those bounding boxes which have good confidence score and good probability score\n",
    "for doing this we will filter the data by confidence score and then by probability and after that apply non maximum suppression method\n",
    "available directly in OpenCV\n",
    "\"\"\"\n",
    "#step 1: filter detection based on confidence score (0.4) and probability score (0.25)\n",
    "        # also take values of center_X, center_y,w,h and reconvert that into original values xmin,xmax,ymin,ymax\n",
    "# Flatten the preds \n",
    "detections = preds[0]\n",
    "# empty list to store the bounding boxes info, confidence score and prob score of each class\n",
    "boxes = []\n",
    "confidences = []\n",
    "classes = []\n",
    "\n",
    "#width and height of the image(input)\n",
    "image_w, image_h = input_image.shape[:2]\n",
    "# using the input image to get the x factor --factor with which to multiply the bounding box \n",
    "x_factor = image_w/INPUT_WH_YOLO\n",
    "y_factor = image_h/INPUT_WH_YOLO\n",
    "\n",
    "# filter \n",
    "for i in range(len(detections)):\n",
    "    row = detections[i]\n",
    "    confidence = row[4]       # confidence score for detecting an object \n",
    "    if confidence > 0.4:\n",
    "        class_score = row[5:].max()    # maximum probability from 20 objects\n",
    "        class_id = row[5:].argmax()    # index position of maximum probability occurence \n",
    "        \n",
    "        if class_score > 0.25:\n",
    "            cx, cy, w, h = row[:4]\n",
    "            # construct bounding box from teh above four values \n",
    "            left = int((cx - 0.5*w)*x_factor)\n",
    "            top = int((cy - 0.5*h)*y_factor)\n",
    "            width = int(w*x_factor)\n",
    "            height = int(h*y_factor)\n",
    "            \n",
    "            box = np.array([left, top, width, height])\n",
    "            # append values into the list \n",
    "            confidences.append(confidence)\n",
    "            boxes.append(box)\n",
    "            classes.append(class_id)\n",
    "\n",
    "\n",
    "# Cleaning \n",
    "boxes_np = np.array(boxes).tolist()\n",
    "confidences_np = np.array(confidences).tolist()\n",
    "\n",
    "# NMS --- non maximum suppression  -- params (boxes, score, score_threshold, nms_threshold)\n",
    "index = cv.dnn.NMSBoxes(boxes_np, confidences_np, 0.25, 0.45).flatten()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e897610f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person: 57%\n",
      "person: 53%\n",
      "person: 52%\n",
      "bus: 44%\n",
      "car: 41%\n"
     ]
    }
   ],
   "source": [
    "# from the index position that we get from above, Draw the bounding boxes \n",
    "\n",
    "for i in index:\n",
    "    # Extract bounding boxes\n",
    "    x,y,w,h = boxes_np[i]\n",
    "    # Extractthe confidences \n",
    "    bb_conf = int(confidences_np[i]*100)\n",
    "    # extract the class\n",
    "    class_id = classes[i]\n",
    "    class_name = labels[class_id]\n",
    "    \n",
    "    text = f'{class_name}: {bb_conf}%'\n",
    "    print(text)\n",
    "    \n",
    "    cv.rectangle(image,(x,y),(x+w,y+h), (0,255,0),2)\n",
    "    cv.rectangle(image,(x,y-30),(x+w,y),(255,255,255),-1)\n",
    "    cv.putText(image,text,(x,y-10),cv.FONT_HERSHEY_PLAIN,0.7,(0,0,0),1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "744e38a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow('Original', img)\n",
    "cv.imshow('yolo_predictions', image)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c19295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287870d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

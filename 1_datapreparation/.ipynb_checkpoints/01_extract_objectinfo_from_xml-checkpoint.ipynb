{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84d4863e",
   "metadata": {},
   "source": [
    "# AFTER APPLYING ALL THESE COMMANDS ON THE DATA AND \n",
    "*\"\"\"\n",
    "1.LOADING XML FILES \n",
    "2.BASIC CLEANING\n",
    "3.PARSING AND EXTRACTING \n",
    "4.CONVERTING INTO DATAFRAMES\n",
    "5.PREPARING LABELS FOR YOLO MODEL\n",
    "6.DATASET SPLITTING INTO TRAIN AND TEST \n",
    "7.LABEL ENCODING \n",
    "8.FOLDER CREATIONS AND SAVING WITH TXT FILE\n",
    "\"\"\"\n",
    "THE CELLS IF OPERATED AGAIN WILL GIVE ERRORS AS AL THE DATA IS MOVED TO RESPECTIVE FOLDERS AND ALL THE OPERATIONS ALREADY DONE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f14c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# few libraries used \n",
    "import os\n",
    "from glob import glob\n",
    "\"\"\" The glob module, which is short for global, is a function that's used to search for files that match a specific file pattern or name. \n",
    "It can be used to search CSV files, for text in files. for xml files.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from xml.etree import ElementTree as et\n",
    "\"\"\"\n",
    "The xml.etree.ElementTree module implements a simple and efficient API for parsing and creating XML data.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f26a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all Xml files and store in a list \n",
    "xml_list = glob('./data_images/*.xml')\n",
    "\"\"\"\n",
    "using the glob library open the file location of the xml files and using the regular expressions command ----- \n",
    "                for extracting all the information in the xml files \n",
    "                file location from where to retrieve from\n",
    "                * -- indicates choosing 'all'\n",
    "                .xml -- file type to choose \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb68138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic cleaning \n",
    "# like replacing the double backwards slash with forward slash\n",
    "\n",
    "xml_list = list(map(lambda x:x.replace('\\\\', '/'), xml_list))   \n",
    "\"\"\"\n",
    "# changing the slashes then using the map function to apply the change to every file in the xml_list file \n",
    "and then converting it into a list and saving it in the same file \n",
    "\n",
    "map functions takes parameters 'functions' and 'iterables' on which the function is applied for each item of the iterable\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e28de18",
   "metadata": {},
   "source": [
    "XML is an inherently hierarchical data format, and the most natural way to represent it is with a tree. ET has two classes for this purpose - ElementTree represents the whole XML document as a tree, and Element represents a single node in this tree. Interactions with the whole document (reading and writing to/from files) are usually done on the ElementTree level. Interactions with a single XML element and its sub-elements are done on the Element level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16365765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the xml files and from each xml file ---\n",
    "\"\"\"\n",
    "extract \n",
    "1.filename \n",
    "2.size(width and height of the image)\n",
    "3.object(name, xmin, xmax, ymin, ymax)\n",
    "\"\"\"\n",
    "# parsing one xml file\n",
    "tree = et.parse('./data_images\\\\00026.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# Extract filename \n",
    "image_name = root.find('filename').text       # inside the find method use the tag name where the file name is written and convert it into text \n",
    "# Extract width and heigth of the image \n",
    "image_width = root.find('size').find('width').text    # for nested tags we use find as many times as the nested tags\n",
    "image_height = root.find('size').find('height').text\n",
    "\n",
    "# extract the object information\n",
    "# since the image can contain many objects so we need to use a for loop for traversing through all the inforamtion\n",
    "parser = []        # create an empty list \n",
    "objs = root.findall('object')    # for getting the information of all the objects in the image \n",
    "for obj in objs:\n",
    "    name = obj.find('name').text                   \n",
    "    boundbox = obj.find('bndbox')    \n",
    "    xmin = boundbox.find('xmin').text\n",
    "    ymin = boundbox.find('ymin').text\n",
    "    xmax = boundbox.find('xmax').text\n",
    "    ymax = boundbox.find('ymax').text\n",
    "    #print(list([image_name, image_width, image_height, name, xmin, xmax, ymin, ymax]))    # or can write as\n",
    "    parser.append([image_name, image_width, image_height, name, xmin, xmax, ymin, ymax])\n",
    "print(f\"{parser} \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869bed6a",
   "metadata": {},
   "source": [
    "# Extracting information for one image\n",
    "\n",
    "obj = root.findall('object')\n",
    "name = obj[0].find('name').text     # the object instance and indexing used to access the infromation of the object \n",
    "# boundbox = root.find('object').find('bndbox')    # creating bounding box instance\n",
    "# or can write as\n",
    "boundbox = obj[0].find('bndbox')\n",
    "xmin = boundbox.find('xmin').text\n",
    "ymin = boundbox.find('ymin').text\n",
    "xmax = boundbox.find('xmax').text\n",
    "ymax = boundbox.find('ymax').text\n",
    "list([name, xmin, xmax, ymin, ymax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3770de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE ABOVE CODE OF PARSING AND EXTRACTING THE INFORMATION FOR ONE FILE CAN BE FUNCTIONISED \n",
    "def extract_text(filename):\n",
    "    tree = et.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    image_name = root.find('filename').text       \n",
    "    image_width = root.find('size').find('width').text   \n",
    "    image_height = root.find('size').find('height').text\n",
    "    parser = []       \n",
    "    objs = root.findall('object')    \n",
    "    for obj in objs:\n",
    "        name = obj.find('name').text                   \n",
    "        boundbox = obj.find('bndbox')    \n",
    "        xmin = boundbox.find('xmin').text\n",
    "        ymin = boundbox.find('ymin').text\n",
    "        xmax = boundbox.find('xmax').text\n",
    "        ymax = boundbox.find('ymax').text\n",
    "        parser.append([image_name, image_width, image_height, name, xmin, ymin, xmax, ymax])\n",
    "    return parser\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0890eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply for all the xml files \n",
    "\n",
    "parser_all = list(map(extract_text, xml_list))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d7f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(parser_all)       # the lenght of the parser_all is equal to the number of images in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dcbac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To flatten the dimensions of the parser_all list\n",
    "# the flattened list will become the data for machine learning operations ---- \n",
    "# use reduce function to decrease the dimensionality of the vector\n",
    "\n",
    "data = reduce(lambda x, y : x+y, parser_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4b5ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the data into DataFrame--easier to read and operate on\n",
    "\n",
    "data_df = pd.DataFrame(data, columns=['Filename', 'Image_width', 'Image_height','Name', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16551008",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Name'].value_counts()    # these will be our classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5488c2e",
   "metadata": {},
   "source": [
    "# Preparing labels for yolo model\n",
    "* for yolo we require the following information\n",
    "1. Center_X  : center position x coordinate of the object normalized to width of the image \n",
    "2. Center_y  : center position y coordinate of the object normalized to height of the image \n",
    "3. w  : width of bounding box normalized to width of the image \n",
    "4. h  : height of the bounding box normalized to height of the image \n",
    "\n",
    "* Let image be 500*300 \n",
    "  bounding box : [car, 50, 100, 220, 200] ([obj_name, xmin, ymin, xmax, ymax])\n",
    "  convert this information into ([obj_name, center_x, center_y, w, h])\n",
    "  #Conversion formula :\n",
    "  1. center_x = (xmin+xmax/2)/width of the image \n",
    "  2. center_y = (ymin+ymax/2)/height of the image\n",
    "  3. w = xmax-xmin/width of the image \n",
    "  4. h = ymax-ymin/height of the image "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd556dc",
   "metadata": {},
   "source": [
    "# FOLDER FORMAT FOR STORING THE ABOVE INFORMATION:\n",
    "data_images  -------- train(training dataset)--- for each image the relevant information must be stored in '.txt' file \n",
    "            --------- test (validate the results)--- similarily as the train data set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e44f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion of information\n",
    "data_df.info()                 \n",
    "# All the columns are in object data type--- for width, height,xmin,xmax, ymin,ymax --all the information needs to be in either int or float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a216a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Type conversion\n",
    "# creating thelist of columns where we want the type conversion\n",
    "cols = ['Image_width', 'Image_height', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "data_df[cols] = data_df[cols].astype('int')       # By default the int data type is int64 for int32 we can use 'int32'\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0125462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the formula for yolo labels :\n",
    "\n",
    "#center_x, center_y\n",
    "data_df['center_x'] = ((data_df['xmin']+data_df['xmax'])/2)/data_df['Image_width']         # adding the column to the dataframe \n",
    "data_df['center_y'] = ((data_df['ymin']+data_df['ymax'])/2)/data_df['Image_height']\n",
    "\n",
    "# w\n",
    "data_df['w'] = (data_df['xmax']-data_df['xmin'])/data_df['Image_width']\n",
    "# h\n",
    "data_df['h'] = (data_df['ymax']-data_df['ymin'])/data_df['Image_height']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f6ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f01e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = data_df['Filename'].unique()\n",
    "len(images)            # split this 503 images into train and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b653829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the images array into dataFrame \n",
    "img_df = pd.DataFrame(images, columns=['Filename'])\n",
    "img_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900c3518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset splitting \n",
    "\n",
    "img_train = tuple(img_df.sample(frac=0.8)['Filename'])                 \n",
    "# sample method shuffles and splits at given %age----- change into a tuple using a function tuple\n",
    "# in test dataset the images we want are the files not in img_train\n",
    "img_test = tuple(img_df.query(f'Filename not in {img_train}')['Filename'])   \n",
    "# rest 20% images in the img_df---- query method takes string expression as a parameter\n",
    "len(img_train), len(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c92f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now split into training and testing DataFrame \n",
    "\n",
    "train_df = data_df.query(f'Filename in {img_train}')\n",
    "test_df = data_df.query(f'Filename in {img_test}')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d154f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a19bb4",
   "metadata": {},
   "source": [
    "# Changing object names into specific ids ---- deep learning model cannot be trained on text \n",
    "# LABEL ENCODING --- CHANGING THE DATATYPE OF CLASSES FROM STRING TO NUMBERS \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7f1bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign id number to object names \n",
    "\n",
    "# label encoding \n",
    "def label_encoding(x):\n",
    "    # creating a dictionary of object names and ids as key:value pairs and return the ids \n",
    "    labels = {'person':0, 'car':1, 'chair':2, 'bottle':3, 'potted plant':4, 'sheep':5, 'cow':6,'boat':7,\n",
    "              'horse':8, 'motor bike':9, 'bicycle':10, 'dog':11, 'bird':12, 'sofa':13, 'bus':14, 'tv monitor':15,\n",
    "              'cat':16, 'train':17, 'aeroplane':18, 'dining table':19}\n",
    "    return labels[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c9f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the ids to train and test set\n",
    "\n",
    "train_df['id'] = train_df['Name'].apply(label_encoding)\n",
    "test_df['id'] = test_df['Name'].apply(label_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42786c8",
   "metadata": {},
   "source": [
    "# Creating Folder Structure for train and test folders ----- each willl store the respective images and text file containing the information(yolo coordinates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36018793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE IMAGES AND LABELS IN TEXT\n",
    "\n",
    "import os \n",
    "from shutil import move \n",
    "\"\"\"\n",
    "The shutil module offers a number of high-level operations on files and collections of files. \n",
    "In particular, functions are provided which support file copying and removal.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c54eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train and test folders inside the data_images folder using python commands and os module\n",
    "\n",
    "train_folder = 'data_images/train'\n",
    "test_folder = 'data_images/test'\n",
    "\n",
    "os.mkdir(train_folder)\n",
    "os.mkdir(test_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c82d1ac",
   "metadata": {},
   "source": [
    "A groupby object in pandas is like a collection of smaller DataFrames, each corresponding to a group defined by the unique values in the 'Filename' column.\n",
    ".groupby('Filename'): This groups the resulting DataFrame by the values in the 'Filename' column.\n",
    "\n",
    "    Each group will contain rows where the 'Filename' column has the same value.\n",
    "    The result is a groupby object (groupby_obj_train) that contains groups of rows, where each group corresponds to a unique value in the 'Filename' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee572db",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Filename', 'id', 'center_x', 'center_y', 'w', 'h']\n",
    "groupby_obj_train = train_df[columns].groupby('Filename')\n",
    "groupby_obj_test = test_df[columns].groupby('Filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d5e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a sample data and store this information in a txt file \n",
    "groupby_obj_train.get_group('00004.jpg').set_index('Filename').to_csv('sample.txt', index = False, header=False)\n",
    "\"\"\".set_index('Filename')\n",
    "    This changes the index of the DataFrame to the 'Filename' column.\n",
    "    The set_index('Filename') method sets the 'Filename' column as the new row index of the DataFrame.\n",
    "    The 'Filename' column is no longer treated as part of the normal data columns and is instead used as the index for rows.\n",
    "\n",
    "   .to_csv('sample.txt', index=False, header=False):\n",
    "\n",
    "    to_csv('sample.txt'): This writes the DataFrame (after the grouping and setting the index) to a file named 'sample.txt' in CSV format.\n",
    "    index=False: This tells pandas not to write the DataFrame index (in this case, the 'Filename' column which was set as the index) to the CSV file.\n",
    "    header=False: This tells pandas not to include the header row (i.e., the column names) in the CSV file.\n",
    "\"\"\"\n",
    "# we need to save the text file without the commas and just with seperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2594bcc",
   "metadata": {},
   "source": [
    "# IDEA -- SAVE EACH IMAGE IN TRAIN OR TEST FOLDER AND RESPECTIVE LABELS IN '.txt' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93a0f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save data in folders \n",
    "\n",
    "def save_data(filename, folder_path, group_obj):\n",
    "    # move the image from source to destination\n",
    "    src = os.path.join('data_images', filename)\n",
    "    dst = os.path.join(folder_path, filename)\n",
    "    move(src, dst)     # move method for moving files\n",
    "    \n",
    "    # saving the labels :\n",
    "    #convert to txt file extension and save the file in the same folder as the iamges \n",
    "    text_filename = os.path.join(folder_path, \n",
    "                                 os.path.splitext(filename)[0] + '.txt')        # [0] index for file name before the dot\n",
    "    group_obj.get_group(filename).set_index('Filename').to_csv(text_filename,sep = ' ',index = False,header=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d9284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below are all the filenames that need to be applied to the save_data function\n",
    "# groupby_obj_train.groups.keys() ----- convert into Series object for easier computations \n",
    "filename_train_series = pd.Series(groupby_obj_train.groups.keys())\n",
    "filename_train_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de4401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the save_data function on few first to test\n",
    "\n",
    "filename_train_series.apply(save_data, args=(train_folder,groupby_obj_train))    \n",
    "# apply-----fucntion and arguements of that function --here folder_path and group_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e670661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_test_series = pd.Series(groupby_obj_test.groups.keys())\n",
    "filename_test_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d97db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_test_series.apply(save_data, args=(test_folder,groupby_obj_test))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f022503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
